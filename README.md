Text detection and recognition from images is a technology with ap- plications ranging from document digitization to assistive technologies for visually impaired individuals. 
This project uses state-of-the-art Optical Character Recognition (OCR) models to extract text from images and convert it into audio. 
The system is trained using the MJSynth dataset and the performance of three OCR approaches, Google Tesseract OCR, EasyOCR, and Keras OCR, are compared. 
These models are evaluated on metrics such as precision, recall, and F1-score. 
To enhance accessibility, the detected text is converted into audio using a Python text-to-speech (TTS) library, pyttsx3. 
The system is designed to assist visually impaired individuals by enabling them to ”read” text from images through audio feedback.
